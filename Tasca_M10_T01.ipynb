{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddenebb/estructures_Dataframe/blob/Clean-Easter-Week/Tasca_M10_T01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im8fYmJH9bL_"
      },
      "source": [
        "# Exercise 1\n",
        "\n",
        "Perform web scraping of two of the three proposed web pages using BeautifulSoup first and Selenium afterwards.\n",
        "\n",
        "- http://quotes.toscrape.com\n",
        "\n",
        "- https://www.bolsamadrid.es\n",
        "\n",
        "- www.wikipedia.es (do a search first and scrape some content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiJ0ZV4U8eqo"
      },
      "source": [
        "Before performing web scraping on any website, it's important to determine whether it is legal and ethical to do so. Here are a few steps that can be taken to determine if web scraping a particular website is allowed:\n",
        "\n",
        "- Check the website's terms of service or robots.txt file: The terms of service or robots.txt file on the website may explicitly prohibit web scraping or provide guidelines for how web scraping can be performed on the site. It's important to read and understand these guidelines before performing any web scraping.\n",
        "\n",
        "- Check for any applicable laws or regulations: In some cases, web scraping may be illegal under certain laws or regulations. For example, the General Data Protection Regulation (GDPR) in the European Union provides guidelines for how personal data can be collected and processed.\n",
        "\n",
        "- Determine the purpose and scope of the web scraping: If the web scraping is for personal or non-commercial use, it may be more likely to be considered legal and ethical than if it is for commercial or competitive purposes. It's also important to consider the scope of the web scraping, including the frequency and volume of requests and the impact on the website's servers.\n",
        "\n",
        "- Obtain permission from the website owner: If in doubt, it's always a good idea to contact the website owner and ask for permission before performing any web scraping. This can help ensure that the web scraping is legal and ethical and can also help establish a positive relationship with the website owner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlksL3R6-A4P"
      },
      "source": [
        "As this is an exercise and will not be used for commercial purposes, we´ll assume that scraping won't be a problem.\n",
        "The website is specifically designed for learning and testing web scraping techniques and does not have any restrictions or prohibitions against web scraping. Additionally, the website provides a robots.txt file that allows web crawling of all pages.\n",
        "However, it's always a good idea to be respectful and responsible when performing web scraping, even on a website that is designed for this purpose. This includes avoiding excessive scraping that could negatively impact the website's servers and being mindful of any potential ethical considerations related to the data being scraped.\n",
        "\n",
        "We will send a request to the website, get its content, and parse it using BeautifulSoup. We will then find all the quote tags on the page and loop through each quote, extracting the text and author information and printing it to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxC8Ode4-naB",
        "outputId": "0b3e5f57-590f-419d-b9dd-858259bce9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albert Einstein: \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"\n",
            "J.K. Rowling: \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"\n",
            "Albert Einstein: \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n",
            "Jane Austen: \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"\n",
            "Marilyn Monroe: \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"\n",
            "Albert Einstein: \"“Try not to become a man of success. Rather become a man of value.”\"\n",
            "André Gide: \"“It is better to be hated for what you are than to be loved for what you are not.”\"\n",
            "Thomas A. Edison: \"“I have not failed. I've just found 10,000 ways that won't work.”\"\n",
            "Eleanor Roosevelt: \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"\n",
            "Steve Martin: \"“A day without sunshine is like, you know, night.”\"\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# send a request to the website and get its content\n",
        "response = requests.get('http://quotes.toscrape.com/')\n",
        "content = response.content\n",
        "\n",
        "# parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# find all the quote tags on the page\n",
        "quote_tags = soup.find_all('div', {'class': 'quote'})\n",
        "\n",
        "# loop through each quote and extract the text and author\n",
        "for quote in quote_tags:\n",
        "    text = quote.find('span', {'class': 'text'}).text\n",
        "    author = quote.find('small', {'class': 'author'}).text\n",
        "    print(f'{author}: \"{text}\"')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJqr5I4SBLvL"
      },
      "source": [
        "We now will do the scraping using Selenium. We first install and import the libraries needed webdriver module from Selenium, and specify the path to the Chrome driver executable. We then initialize a Chrome driver and navigate to the website using the get method. We get the page source using the page_source property of the driver object and parse it using BeautifulSoup. Finally, we find all the quote tags on the page, loop through them, and extract the text and author using the same methods as in the previous example. We then close the driver using the quit method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SisT8tnRVaqw",
        "outputId": "ee41fdb7-e3a1-4467-bdd8-d29998b5646c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-08 20:41:15--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.63.136, 172.253.63.190, 172.253.63.93, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.63.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93762720 (89M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.2’\n",
            "\n",
            "google-chrome-stabl 100%[===================>]  89.42M   295MB/s    in 0.3s    \n",
            "\n",
            "2023-04-08 20:41:15 (295 MB/s) - ‘google-chrome-stable_current_amd64.deb.2’ saved [93762720/93762720]\n",
            "\n",
            "(Reading database ... 122582 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (112.0.5615.49-1) over (112.0.5615.49-1) ...\n",
            "Setting up google-chrome-stable (112.0.5615.49-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "!apt-get -f install -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ6LizDrVjvT",
        "outputId": "08cea880-7f17-4927-dd11-04ee07d2b0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7181:7181:0408/204133.875243:ERROR:zygote_host_impl_linux.cc(100)] Running as root without --no-sandbox is not supported. See https://crbug.com/638180.\n"
          ]
        }
      ],
      "source": [
        "!google-chrome-stable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr2gJvsMqNY_",
        "outputId": "c4cce210-0e9d-479f-a1c9-6678a51816ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#docs_dir = '/content/gdrive/My Drive/Docs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-D6MvTAZVG7",
        "outputId": "dcac2329-0716-4730-d9a4-e86947289d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Chrome 112.0.5615.49 \n"
          ]
        }
      ],
      "source": [
        "!google-chrome --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LjER75pz1hAE"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Google Colab DS IT Academy/Sprint 10/Data/chromedriver\" /usr/bin/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2YhUoOK52HvX"
      },
      "outputs": [],
      "source": [
        "!sudo chmod +x /usr/bin/chromedriver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZVD30ZSZiSC",
        "outputId": "c1ba6572-fccd-4ef8-9002-48c715b71201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromeDriver 111.0.5563.64 (c710e93d5b63b7095afe8c2c17df34408078439d-refs/branch-heads/5563@{#995})\n"
          ]
        }
      ],
      "source": [
        "!chromedriver --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY-tmsAySe0f",
        "outputId": "c33f8bcf-6c90-4a59-d11c-1657ae46110a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.9/dist-packages (4.8.3)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.9/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.9/dist-packages (from selenium) (1.26.15)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.10.2)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (22.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.9/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5yOGLFbCILm"
      },
      "source": [
        "It's important to note that using Selenium can be slower and more resource-intensive than using Beautiful Soup, as it involves opening a full browser window and loading the page. However, it can be useful in cases where the website requires user interaction, such as filling out forms or clicking buttons, as Selenium can simulate user actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "renZJLtxbqwH",
        "outputId": "79cfab72-cd12-492f-ee45-d62705a1d383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-85c35e47d838>:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chromedriver_path, options=options)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albert Einstein: \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"\n",
            "J.K. Rowling: \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"\n",
            "Albert Einstein: \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n",
            "Jane Austen: \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"\n",
            "Marilyn Monroe: \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"\n",
            "Albert Einstein: \"“Try not to become a man of success. Rather become a man of value.”\"\n",
            "André Gide: \"“It is better to be hated for what you are than to be loved for what you are not.”\"\n",
            "Thomas A. Edison: \"“I have not failed. I've just found 10,000 ways that won't work.”\"\n",
            "Eleanor Roosevelt: \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"\n",
            "Steve Martin: \"“A day without sunshine is like, you know, night.”\"\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--no-sandbox')\n",
        "\n",
        "# Point to the location of your chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome(chromedriver_path, options=options)\n",
        "\n",
        "# Wait for the page to load and get the content\n",
        "wait = WebDriverWait(driver, 10)\n",
        "driver.get('http://quotes.toscrape.com/')\n",
        "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.quote')))\n",
        "\n",
        "# get the page source and parse it using BeautifulSoup\n",
        "content = driver.page_source\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# find all the quote tags on the page\n",
        "quote_tags = soup.find_all('div', {'class': 'quote'})\n",
        "\n",
        "# loop through each quote and extract the text and author\n",
        "for quote in quote_tags:\n",
        "    text = quote.find('span', {'class': 'text'}).text\n",
        "    author = quote.find('small', {'class': 'author'}).text\n",
        "    print(f'{author}: \"{text}\"')\n",
        "\n",
        "# close the driver\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wredNRWU9bx8"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "Document your data set generated with the information in the different Kaggle files in a Word document.\n",
        "\n",
        "To know more\n",
        "\n",
        "As an example of what is requested, you can consult this link:\n",
        "\n",
        "->https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Famous Quotes\n",
        "\n",
        "Description: This dataset contains a collection of famous quotes from various authors.\n",
        "\n",
        "Columns:\n",
        "\n",
        "    author: The name of the author who wrote the quote. (string)\n",
        "    quote: The text of the quote. (string)\n",
        "\n",
        "Rows:\n",
        "\n",
        "The dataset contains 10 rows, each representing a famous quote from a different author.\n",
        "\n",
        "Example Rows:\n",
        "\n",
        "| author          | quote                                                                                     |\n",
        "|----------------|-------------------------------------------------------------------------------------------|\n",
        "| Albert Einstein | “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” |\n",
        "| J.K. Rowling    | “It is our choices, Harry, that show what we truly are, far more than our abilities.”         |\n",
        "| Jane Austen     | “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” |\n",
        "| Marilyn Monroe  | “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” |\n",
        "| André Gide      | “It is better to be hated for what you are than to be loved for what you are not.”            |\n",
        "| Thomas A. Edison| “I have not failed. I've just found 10,000 ways that won't work.”                             |\n",
        "| Eleanor Roosevelt| “A woman is like a tea bag; you never know how strong it is until it's in hot water.”        |\n",
        "| Steve Martin    | “A day without sunshine is like, you know, night.”                                          |\n",
        "\n"
      ],
      "metadata": {
        "id": "J8UdutxzsNbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "\n",
        "markdown_text = '''\n",
        "# Title: Famous Quotes\n",
        "\n",
        "Description: This dataset contains a collection of famous quotes from various authors.\n",
        "\n",
        "Columns:\n",
        "\n",
        "    author: The name of the author who wrote the quote. (string)\n",
        "    quote: The text of the quote. (string)\n",
        "\n",
        "Rows:\n",
        "\n",
        "The dataset contains 10 rows, each representing a famous quote from a different author.\n",
        "\n",
        "Example Rows:\n",
        "\n",
        "| author          | quote                                                                                     |\n",
        "|----------------|-------------------------------------------------------------------------------------------|\n",
        "| Albert Einstein | “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” |\n",
        "| J.K. Rowling    | “It is our choices, Harry, that show what we truly are, far more than our abilities.”         |\n",
        "| Jane Austen     | “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” |\n",
        "| Marilyn Monroe  | “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” |\n",
        "| André Gide      | “It is better to be hated for what you are than to be loved for what you are not.”            |\n",
        "| Thomas A. Edison| “I have not failed. I've just found 10,000 ways that won't work.”                             |\n",
        "| Eleanor Roosevelt| “A woman is like a tea bag; you never know how strong it is until it's in hot water.”        |\n",
        "| Steve Martin    | “A day without sunshine is like, you know, night.”                                          |\n",
        "'''\n",
        "\n",
        "output = pypandoc.convert_text(markdown_text, 'docx', format='md', outputfile='Famous_Quotes_info.docx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLoNNgW2uP4U",
        "outputId": "8ed66faf-7871-4a86-de21-336f7d04e405"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[DEBUG] Ensuring pandoc path...\n",
            "DEBUG:pypandoc:Ensuring pandoc path...\n",
            "2023-04-08 21:25:36 [pypandoc] DEBUG: Ensuring pandoc path...\n",
            "[DEBUG] Verifying format...\n",
            "DEBUG:pypandoc:Verifying format...\n",
            "2023-04-08 21:25:37 [pypandoc] DEBUG: Verifying format...\n",
            "[DEBUG] Identifying input type...\n",
            "DEBUG:pypandoc:Identifying input type...\n",
            "2023-04-08 21:25:37 [pypandoc] DEBUG: Identifying input type...\n",
            "[DEBUG] Running pandoc...\n",
            "DEBUG:pypandoc:Running pandoc...\n",
            "2023-04-08 21:25:37 [pypandoc] DEBUG: Running pandoc...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Set the path to the Word document file\n",
        "file_path = '/content/Famous_Quotes_info.docx'\n",
        "\n",
        "# Create an HTML object with an iframe tag\n",
        "html = HTML('<iframe src=\"{0}\" width=700 height=500></iframe>'.format(file_path))\n",
        "\n",
        "# Display the HTML object in your notebook\n",
        "display(html)\n"
      ],
      "metadata": {
        "id": "nd58aGqaxd2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4LT8Y-W9wId"
      },
      "source": [
        "# Exercici 3\n",
        "\n",
        "Choose a web page of your choice and perform web scraping using the Selenium library first and Scrapy later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRTvbTaSADCs"
      },
      "source": [
        "The website 'https://en.wikipedia.org/wiki/Digital_audio_workstation' is a publicly available website that is meant for general information and educational purposes. It allows web scraping under certain conditions. According to the website's terms of use, \"you are free to copy, distribute, transmit, and adapt the work, provided that you give attribution and do not use the material in a way that suggests that the licensor endorses you or your use.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LBDG2VRIfuE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03acff36-3cf7-4af9-af62-7e0777441b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Contents\n",
            "### Integration[edit]\n",
            "### Plug-ins[edit]\n",
            "## Hardware[edit]\n",
            "### Integration[edit]\n",
            "### Plug-ins[edit]\n",
            "## Software[edit]\n",
            "### Plug-ins[edit]\n",
            "## Notable commercial examples[edit]\n",
            "## See also[edit]\n",
            "## Notes[edit]\n",
            "## References[edit]\n",
            "## External links[edit]\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--no-sandbox')\n",
        "\n",
        "# Point to the location of your chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome(chromedriver_path, options=options)\n",
        "\n",
        "# Navigate to the page\n",
        "driver.get('https://en.wikipedia.org/wiki/Digital_audio_workstation')\n",
        "\n",
        "# Wait for the page to load and get the content\n",
        "wait = WebDriverWait(driver, 10)\n",
        "content = wait.until(EC.presence_of_element_located((By.ID, 'content')))\n",
        "\n",
        "# Get the page source and parse it using BeautifulSoup\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "# Find all the h2 elements and extract their text\n",
        "h2s = soup.find_all('h2')\n",
        "for h2 in h2s:\n",
        "    print('## ' + h2.text.strip())\n",
        "    \n",
        "    # Find all the h3 elements under the current h2 and extract their text\n",
        "    h3s = h2.find_all_next('h3')\n",
        "    for h3 in h3s:\n",
        "        print('### ' + h3.text.strip())\n",
        "    \n",
        "# Close the driver\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "\n",
        "class DAWSpider(scrapy.Spider):\n",
        "    name = \"daw\"\n",
        "    start_urls = [\n",
        "        \"https://en.wikipedia.org/wiki/Digital_audio_workstation\"\n",
        "    ]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for h2 in response.css('h2'):\n",
        "            header = '## ' + h2.css('span.mw-headline::text').get()\n",
        "            yield {\n",
        "                'header': header\n",
        "            }"
      ],
      "metadata": {
        "id": "Rdb7_uN8j2D5"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Vyj8BYm1mj9Cj6w3veMQG1Ec51YgcrDG",
      "authorship_tag": "ABX9TyN13g9FY2gVc4zAiQrsP9vh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}