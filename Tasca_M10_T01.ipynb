{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddenebb/estructures_Dataframe/blob/Selenium-not-finding-table/Tasca_M10_T01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im8fYmJH9bL_"
      },
      "source": [
        "# Exercise 1\n",
        "\n",
        "Perform web scraping of two of the three proposed web pages using BeautifulSoup first and Selenium afterwards.\n",
        "\n",
        "- http://quotes.toscrape.com\n",
        "\n",
        "- https://www.bolsamadrid.es\n",
        "\n",
        "- www.wikipedia.es (do a search first and scrape some content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiJ0ZV4U8eqo"
      },
      "source": [
        "Before performing web scraping on any website, it's important to determine whether it is legal and ethical to do so. Here are a few steps that can be taken to determine if web scraping a particular website is allowed:\n",
        "\n",
        "- Check the website's terms of service or robots.txt file: The terms of service or robots.txt file on the website may explicitly prohibit web scraping or provide guidelines for how web scraping can be performed on the site. It's important to read and understand these guidelines before performing any web scraping.\n",
        "\n",
        "- Check for any applicable laws or regulations: In some cases, web scraping may be illegal under certain laws or regulations. For example, the General Data Protection Regulation (GDPR) in the European Union provides guidelines for how personal data can be collected and processed.\n",
        "\n",
        "- Determine the purpose and scope of the web scraping: If the web scraping is for personal or non-commercial use, it may be more likely to be considered legal and ethical than if it is for commercial or competitive purposes. It's also important to consider the scope of the web scraping, including the frequency and volume of requests and the impact on the website's servers.\n",
        "\n",
        "- Obtain permission from the website owner: If in doubt, it's always a good idea to contact the website owner and ask for permission before performing any web scraping. This can help ensure that the web scraping is legal and ethical and can also help establish a positive relationship with the website owner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlksL3R6-A4P"
      },
      "source": [
        "As this is an exercise and will not be used for commercial purposes, we´ll assume that scraping won't be a problem.\n",
        "The website is specifically designed for learning and testing web scraping techniques and does not have any restrictions or prohibitions against web scraping. Additionally, the website provides a robots.txt file that allows web crawling of all pages.\n",
        "However, it's always a good idea to be respectful and responsible when performing web scraping, even on a website that is designed for this purpose. This includes avoiding excessive scraping that could negatively impact the website's servers and being mindful of any potential ethical considerations related to the data being scraped.\n",
        "\n",
        "We will send a request to the website, get its content, and parse it using BeautifulSoup. We will then find all the quote tags on the page and loop through each quote, extracting the text and author information and printing it to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxC8Ode4-naB",
        "outputId": "b4511e33-ff5f-4e45-e318-ad3c431ea7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albert Einstein: \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"\n",
            "J.K. Rowling: \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"\n",
            "Albert Einstein: \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n",
            "Jane Austen: \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"\n",
            "Marilyn Monroe: \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"\n",
            "Albert Einstein: \"“Try not to become a man of success. Rather become a man of value.”\"\n",
            "André Gide: \"“It is better to be hated for what you are than to be loved for what you are not.”\"\n",
            "Thomas A. Edison: \"“I have not failed. I've just found 10,000 ways that won't work.”\"\n",
            "Eleanor Roosevelt: \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"\n",
            "Steve Martin: \"“A day without sunshine is like, you know, night.”\"\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# send a request to the website and get its content\n",
        "response = requests.get('http://quotes.toscrape.com/')\n",
        "content = response.content\n",
        "\n",
        "# parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# find all the quote tags on the page\n",
        "quote_tags = soup.find_all('div', {'class': 'quote'})\n",
        "\n",
        "# loop through each quote and extract the text and author\n",
        "for quote in quote_tags:\n",
        "    text = quote.find('span', {'class': 'text'}).text\n",
        "    author = quote.find('small', {'class': 'author'}).text\n",
        "    print(f'{author}: \"{text}\"')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJqr5I4SBLvL"
      },
      "source": [
        "We now will do the scraping using Selenium. We first install and import the libraries needed webdriver module from Selenium, and specify the path to the Chrome driver executable. We then initialize a Chrome driver and navigate to the website using the get method. We get the page source using the page_source property of the driver object and parse it using BeautifulSoup. Finally, we find all the quote tags on the page, loop through them, and extract the text and author using the same methods as in the previous example. We then close the driver using the quit method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SisT8tnRVaqw",
        "outputId": "2e55cec7-79cf-4938-ea63-0949218d89b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-10 10:55:18--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 108.177.13.93, 108.177.13.190, 108.177.13.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|108.177.13.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93762720 (89M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.3’\n",
            "\n",
            "google-chrome-stabl 100%[===================>]  89.42M   327MB/s    in 0.3s    \n",
            "\n",
            "2023-04-10 10:55:19 (327 MB/s) - ‘google-chrome-stable_current_amd64.deb.3’ saved [93762720/93762720]\n",
            "\n",
            "(Reading database ... 122582 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (112.0.5615.49-1) over (112.0.5615.49-1) ...\n",
            "Setting up google-chrome-stable (112.0.5615.49-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "!apt-get -f install -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ6LizDrVjvT",
        "outputId": "03f98c78-7d93-4116-8aaa-0b808a13846f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40213:40213:0410/105540.355630:ERROR:zygote_host_impl_linux.cc(100)] Running as root without --no-sandbox is not supported. See https://crbug.com/638180.\n"
          ]
        }
      ],
      "source": [
        "!google-chrome-stable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr2gJvsMqNY_",
        "outputId": "b55bf057-6961-4957-d529-5d80e9ce2a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#docs_dir = '/content/gdrive/My Drive/Docs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-D6MvTAZVG7",
        "outputId": "be58da78-4f49-43f7-df20-e880d1b63229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Chrome 112.0.5615.49 \n"
          ]
        }
      ],
      "source": [
        "!google-chrome --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LjER75pz1hAE"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/Google Colab DS IT Academy/Sprint 10/Data/chromedriver\" /usr/bin/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2YhUoOK52HvX"
      },
      "outputs": [],
      "source": [
        "!sudo chmod +x /usr/bin/chromedriver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZVD30ZSZiSC",
        "outputId": "09e5d555-6774-44ee-f291-a97940a4b575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromeDriver 112.0.5615.49 (bd2a7bcb881c11e8cfe3078709382934e3916914-refs/branch-heads/5615@{#936})\n"
          ]
        }
      ],
      "source": [
        "!chromedriver --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY-tmsAySe0f",
        "outputId": "21f087d2-7f33-45d9-a445-037227ea9117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.9/dist-packages (4.8.3)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.9/dist-packages (from selenium) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.9/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.10.2)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.9/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (22.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.9/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5yOGLFbCILm"
      },
      "source": [
        "It's important to note that using Selenium can be slower and more resource-intensive than using Beautiful Soup, as it involves opening a full browser window and loading the page. However, it can be useful in cases where the website requires user interaction, such as filling out forms or clicking buttons, as Selenium can simulate user actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "renZJLtxbqwH",
        "outputId": "3236021d-6bc4-4642-8b7b-bccfccc3ff2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-85c35e47d838>:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chromedriver_path, options=options)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Albert Einstein: \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"\n",
            "J.K. Rowling: \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"\n",
            "Albert Einstein: \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n",
            "Jane Austen: \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"\n",
            "Marilyn Monroe: \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"\n",
            "Albert Einstein: \"“Try not to become a man of success. Rather become a man of value.”\"\n",
            "André Gide: \"“It is better to be hated for what you are than to be loved for what you are not.”\"\n",
            "Thomas A. Edison: \"“I have not failed. I've just found 10,000 ways that won't work.”\"\n",
            "Eleanor Roosevelt: \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"\n",
            "Steve Martin: \"“A day without sunshine is like, you know, night.”\"\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--no-sandbox')\n",
        "\n",
        "# Point to the location of your chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome(chromedriver_path, options=options)\n",
        "\n",
        "# Wait for the page to load and get the content\n",
        "wait = WebDriverWait(driver, 10)\n",
        "driver.get('http://quotes.toscrape.com/')\n",
        "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.quote')))\n",
        "\n",
        "# get the page source and parse it using BeautifulSoup\n",
        "content = driver.page_source\n",
        "soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# find all the quote tags on the page\n",
        "quote_tags = soup.find_all('div', {'class': 'quote'})\n",
        "\n",
        "# loop through each quote and extract the text and author\n",
        "for quote in quote_tags:\n",
        "    text = quote.find('span', {'class': 'text'}).text\n",
        "    author = quote.find('small', {'class': 'author'}).text\n",
        "    print(f'{author}: \"{text}\"')\n",
        "\n",
        "# close the driver\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wredNRWU9bx8"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "Document your data set generated with the information in the different Kaggle files in a Word document.\n",
        "\n",
        "To know more\n",
        "\n",
        "As an example of what is requested, you can consult this link:\n",
        "\n",
        "->https://www.kaggle.com/datasets/vivovinco/20212022-football-team-stats."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Famous Quotes\n",
        "\n",
        "Description: This dataset contains a collection of famous quotes from various authors.\n",
        "\n",
        "Columns:\n",
        "\n",
        "    author: The name of the author who wrote the quote. (string)\n",
        "    quote: The text of the quote. (string)\n",
        "\n",
        "Rows:\n",
        "\n",
        "The dataset contains 10 rows, each representing a famous quote from a different author.\n",
        "\n",
        "Example Rows:\n",
        "\n",
        "| author          | quote                                                                                     |\n",
        "|----------------|-------------------------------------------------------------------------------------------|\n",
        "| Albert Einstein | “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” |\n",
        "| J.K. Rowling    | “It is our choices, Harry, that show what we truly are, far more than our abilities.”         |\n",
        "| Jane Austen     | “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” |\n",
        "| Marilyn Monroe  | “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” |\n",
        "| André Gide      | “It is better to be hated for what you are than to be loved for what you are not.”            |\n",
        "| Thomas A. Edison| “I have not failed. I've just found 10,000 ways that won't work.”                             |\n",
        "| Eleanor Roosevelt| “A woman is like a tea bag; you never know how strong it is until it's in hot water.”        |\n",
        "| Steve Martin    | “A day without sunshine is like, you know, night.”                                          |\n",
        "\n"
      ],
      "metadata": {
        "id": "J8UdutxzsNbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypandoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_VnAZlsyO5A",
        "outputId": "0572a4f5-3e60-497e-8a61-09c6c0e25b8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.9/dist-packages (1.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "\n",
        "markdown_text = '''\n",
        "# Title: Famous Quotes\n",
        "\n",
        "Description: This dataset contains a collection of famous quotes from various authors.\n",
        "\n",
        "Columns:\n",
        "\n",
        "    author: The name of the author who wrote the quote. (string)\n",
        "    quote: The text of the quote. (string)\n",
        "\n",
        "Rows:\n",
        "\n",
        "The dataset contains 10 rows, each representing a famous quote from a different author.\n",
        "\n",
        "Example Rows:\n",
        "\n",
        "| author          | quote                                                                                     |\n",
        "|----------------|-------------------------------------------------------------------------------------------|\n",
        "| Albert Einstein | “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” |\n",
        "| J.K. Rowling    | “It is our choices, Harry, that show what we truly are, far more than our abilities.”         |\n",
        "| Jane Austen     | “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” |\n",
        "| Marilyn Monroe  | “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” |\n",
        "| André Gide      | “It is better to be hated for what you are than to be loved for what you are not.”            |\n",
        "| Thomas A. Edison| “I have not failed. I've just found 10,000 ways that won't work.”                             |\n",
        "| Eleanor Roosevelt| “A woman is like a tea bag; you never know how strong it is until it's in hot water.”        |\n",
        "| Steve Martin    | “A day without sunshine is like, you know, night.”                                          |\n",
        "'''\n",
        "\n",
        "output = pypandoc.convert_text(markdown_text, 'docx', format='md', outputfile='Famous_Quotes_info.docx')"
      ],
      "metadata": {
        "id": "JLoNNgW2uP4U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4LT8Y-W9wId"
      },
      "source": [
        "# Exercici 3\n",
        "\n",
        "Choose a web page of your choice and perform web scraping using the Selenium library first and Scrapy later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRTvbTaSADCs"
      },
      "source": [
        "The website 'https://en.wikipedia.org/wiki/Digital_audio_workstation' is a publicly available website that is meant for general information and educational purposes. It allows web scraping under certain conditions. According to the website's terms of use, \"you are free to copy, distribute, transmit, and adapt the work, provided that you give attribution and do not use the material in a way that suggests that the licensor endorses you or your use.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LBDG2VRIfuE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881e9d6f-c3fb-4b98-9b16-63db0d5e301f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-8e54f41af122>:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chromedriver_path, options=options)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Contents\n",
            "### Integration[edit]\n",
            "### Plug-ins[edit]\n",
            "## Hardware[edit]\n",
            "### Integration[edit]\n",
            "### Plug-ins[edit]\n",
            "## Software[edit]\n",
            "### Plug-ins[edit]\n",
            "## Notable commercial examples[edit]\n",
            "## See also[edit]\n",
            "## Notes[edit]\n",
            "## References[edit]\n",
            "## External links[edit]\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--no-sandbox')\n",
        "\n",
        "# Point to the location of your chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome(chromedriver_path, options=options)\n",
        "\n",
        "# Navigate to the page\n",
        "driver.get('https://en.wikipedia.org/wiki/Digital_audio_workstation')\n",
        "\n",
        "# Wait for the page to load and get the content\n",
        "wait = WebDriverWait(driver, 10)\n",
        "content = wait.until(EC.presence_of_element_located((By.ID, 'content')))\n",
        "\n",
        "# Get the page source and parse it using BeautifulSoup\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "# Find all the h2 elements and extract their text\n",
        "h2s = soup.find_all('h2')\n",
        "for h2 in h2s:\n",
        "    print('## ' + h2.text.strip())\n",
        "    \n",
        "    # Find all the h3 elements under the current h2 and extract their text\n",
        "    h3s = h2.find_all_next('h3')\n",
        "    for h3 in h3s:\n",
        "        print('### ' + h3.text.strip())\n",
        "    \n",
        "# Close the driver\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Make a request\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_Academy_Award-winning_films'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create soup object\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the awards table\n",
        "table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "\n",
        "# Extract the table headers\n",
        "headers = []\n",
        "for th in table.find_all('th'):\n",
        "    headers.append(th.text.strip())\n",
        "\n",
        "# Extract the table rows\n",
        "rows = []\n",
        "for tr in table.tbody.find_all('tr'):\n",
        "    row = []\n",
        "    for td in tr.find_all('td'):\n",
        "        row.append(td.text.strip())\n",
        "    if row:\n",
        "        rows.append(row)\n",
        "\n",
        "# Create the pandas dataframe\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nGc0S-Wf9xuh",
        "outputId": "fcc67629-fdda-43b9-8226-b179f1e4e9a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Film  Year Awards  \\\n",
              "0                     Everything Everywhere All at Once  2022      7   \n",
              "1                        All Quiet on the Western Front  2022      4   \n",
              "2                                             The Whale  2022      2   \n",
              "3                                     Top Gun: Maverick  2022      1   \n",
              "4                        Black Panther: Wakanda Forever  2022      1   \n",
              "...                                                 ...   ...    ...   \n",
              "1355                            The Yankee Doodle Mouse  1943      1   \n",
              "1356                                       The Yearling  1946      2   \n",
              "1357  Yesterday, Today and Tomorrow (Ieri, oggi, dom...  1964      1   \n",
              "1358                         You Can't Take It with You  1938      2   \n",
              "1359                    Zorba the Greek (Alexis Zorbas)  1964      3   \n",
              "\n",
              "     Nominations  \n",
              "0             11  \n",
              "1              9  \n",
              "2              3  \n",
              "3              6  \n",
              "4              5  \n",
              "...          ...  \n",
              "1355           1  \n",
              "1356           7  \n",
              "1357           1  \n",
              "1358           7  \n",
              "1359           7  \n",
              "\n",
              "[1360 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82e05c4b-05fd-4744-80f5-bdb264fa8ff1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Film</th>\n",
              "      <th>Year</th>\n",
              "      <th>Awards</th>\n",
              "      <th>Nominations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Everything Everywhere All at Once</td>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All Quiet on the Western Front</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Whale</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Top Gun: Maverick</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Black Panther: Wakanda Forever</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>The Yankee Doodle Mouse</td>\n",
              "      <td>1943</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356</th>\n",
              "      <td>The Yearling</td>\n",
              "      <td>1946</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1357</th>\n",
              "      <td>Yesterday, Today and Tomorrow (Ieri, oggi, dom...</td>\n",
              "      <td>1964</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>You Can't Take It with You</td>\n",
              "      <td>1938</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>Zorba the Greek (Alexis Zorbas)</td>\n",
              "      <td>1964</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1360 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82e05c4b-05fd-4744-80f5-bdb264fa8ff1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82e05c4b-05fd-4744-80f5-bdb264fa8ff1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82e05c4b-05fd-4744-80f5-bdb264fa8ff1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code launches the Chrome browser, navigates to the webpage with the table, waits for the table to load, extracts the table headers and rows using XPath, converts the rows into a Pandas dataframe, and then closes the browser."
      ],
      "metadata": {
        "id": "6EPftswUG0CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('--no-sandbox')\n",
        "\n",
        "# Point to the location of your chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "# Initialize the driver\n",
        "driver = webdriver.Chrome(chromedriver_path, options=options)\n",
        "\n",
        "# Navigate to the page\n",
        "driver.get('https://en.wikipedia.org/wiki/Digital_audio_workstation')\n",
        "\n",
        "# Wait for the page to load and get the content\n",
        "wait = WebDriverWait(driver, 10)\n",
        "content = wait.until(EC.presence_of_element_located((By.ID, 'content')))\n",
        "\n",
        "# Get the page source and parse it using BeautifulSoup\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "\n",
        "# Find the awards table\n",
        "table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "\n",
        "# Extract the table headers\n",
        "headers = []\n",
        "for th in table.find_all('th'):\n",
        "    headers.append(th.text.strip())\n",
        "\n",
        "# Extract the table rows\n",
        "rows = []\n",
        "for tr in table.tbody.find_all('tr'):\n",
        "    row = []\n",
        "    for td in tr.find_all('td'):\n",
        "        row.append(td.text.strip())\n",
        "    if row:\n",
        "        rows.append(row)\n",
        "\n",
        "# Create the pandas dataframe\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "fFutTVkA0CzG",
        "outputId": "bf243f60-8c8a-403e-d9a2-e4c5ea4f4048"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-7cc436f2591b>:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chromedriver_path, options=options)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7cc436f2591b>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Extract the table headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapy\n",
        "!pip install scrapy-user-agents\n",
        "!pip install scrapy-rotating-proxies\n"
      ],
      "metadata": {
        "id": "Rdb7_uN8j2D5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0def65b8-8dfd-451f-fcf5-81b14a9c562e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.9/dist-packages (2.8.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (22.10.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (0.8.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (6.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (2.1.1)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (4.9.2)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.9/dist-packages (from scrapy) (1.6.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.9/dist-packages (from scrapy) (0.2.1)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (21.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from scrapy) (23.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.9/dist-packages (from scrapy) (3.4.0)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from scrapy) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from scrapy) (67.6.1)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (1.7.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.9/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.9/dist-packages (from scrapy) (40.0.1)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from scrapy) (1.0.6)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.9/dist-packages (from scrapy) (23.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.9/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.9/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from service-identity>=18.1.0->scrapy) (22.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.9/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.9/dist-packages (from Twisted>=18.9.0->scrapy) (4.5.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.9/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.9/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.9/dist-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from tldextract->scrapy) (3.4)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from tldextract->scrapy) (3.10.7)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.9/dist-packages (from tldextract->scrapy) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from tldextract->scrapy) (2.27.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy-user-agents in /usr/local/lib/python3.9/dist-packages (0.1.1)\n",
            "Requirement already satisfied: user-agents in /usr/local/lib/python3.9/dist-packages (from scrapy-user-agents) (2.2.0)\n",
            "Requirement already satisfied: ua-parser>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from user-agents->scrapy-user-agents) (0.16.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy-rotating-proxies in /usr/local/lib/python3.9/dist-packages (0.6.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.9/dist-packages (from scrapy-rotating-proxies) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.9/dist-packages (from scrapy-rotating-proxies) (22.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from scrapy-rotating-proxies) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy startproject mynuproject\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKBIh3YUHkN4",
        "outputId": "76b6376c-eaa9-4e02-b507-11ad387edc01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: scrapy.cfg already exists in /content/mynuproject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mynuproject && scrapy genspider myspider example.com\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcPvUduvHtZb",
        "outputId": "5fd17776-4624-43ac-994a-415ad73d9ffb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spider 'myspider' already exists in module:\n",
            "  mynuproject.spiders.myspider\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "import pandas as pd\n",
        "\n",
        "class MySpider(scrapy.Spider):\n",
        "    name = 'myspider'\n",
        "    start_urls = ['https://en.wikipedia.org/wiki/List_of_Academy_Award-winning_films']\n",
        "\n",
        "    def parse(self, response):\n",
        "        table = response.css('table')\n",
        "        headers = table.css('th::text').getall()\n",
        "        rows = table.css('tbody tr')\n",
        "        \n",
        "        # Create a list to store the table data\n",
        "        table_data = []\n",
        "        \n",
        "        for row in rows:\n",
        "            data = row.css('td::text').getall()\n",
        "            \n",
        "            # Append the row data to the table data list\n",
        "            table_data.append(data)\n",
        "            \n",
        "        # Convert the table data list to a DataFrame\n",
        "        df = pd.DataFrame(table_data, columns=headers)\n",
        "        \n",
        "        # Show the DataFrame\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f5az4iHqHxTU",
        "outputId": "ac2b69a2-4e6e-483d-cfc9-06233aa295c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Film  Year Awards  \\\n",
              "0                     Everything Everywhere All at Once  2022      7   \n",
              "1                        All Quiet on the Western Front  2022      4   \n",
              "2                                             The Whale  2022      2   \n",
              "3                                     Top Gun: Maverick  2022      1   \n",
              "4                        Black Panther: Wakanda Forever  2022      1   \n",
              "...                                                 ...   ...    ...   \n",
              "1355                            The Yankee Doodle Mouse  1943      1   \n",
              "1356                                       The Yearling  1946      2   \n",
              "1357  Yesterday, Today and Tomorrow (Ieri, oggi, dom...  1964      1   \n",
              "1358                         You Can't Take It with You  1938      2   \n",
              "1359                    Zorba the Greek (Alexis Zorbas)  1964      3   \n",
              "\n",
              "     Nominations  \n",
              "0             11  \n",
              "1              9  \n",
              "2              3  \n",
              "3              6  \n",
              "4              5  \n",
              "...          ...  \n",
              "1355           1  \n",
              "1356           7  \n",
              "1357           1  \n",
              "1358           7  \n",
              "1359           7  \n",
              "\n",
              "[1360 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fa2e464-7b88-42bf-9739-0e5da5f57559\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Film</th>\n",
              "      <th>Year</th>\n",
              "      <th>Awards</th>\n",
              "      <th>Nominations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Everything Everywhere All at Once</td>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All Quiet on the Western Front</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Whale</td>\n",
              "      <td>2022</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Top Gun: Maverick</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Black Panther: Wakanda Forever</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>The Yankee Doodle Mouse</td>\n",
              "      <td>1943</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356</th>\n",
              "      <td>The Yearling</td>\n",
              "      <td>1946</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1357</th>\n",
              "      <td>Yesterday, Today and Tomorrow (Ieri, oggi, dom...</td>\n",
              "      <td>1964</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>You Can't Take It with You</td>\n",
              "      <td>1938</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>Zorba the Greek (Alexis Zorbas)</td>\n",
              "      <td>1964</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1360 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa2e464-7b88-42bf-9739-0e5da5f57559')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fa2e464-7b88-42bf-9739-0e5da5f57559 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fa2e464-7b88-42bf-9739-0e5da5f57559');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Vyj8BYm1mj9Cj6w3veMQG1Ec51YgcrDG",
      "authorship_tag": "ABX9TyMAeQ4Sdr1mVL0g2HGLmF05",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}